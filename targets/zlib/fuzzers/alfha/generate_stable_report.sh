#!/bin/bash
set -e

# ALFHA zlib Stable Coverage Report Generator
# Creates unified report from stable harnesses only

ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROFILE_DIR="$ROOT/stable_profiles"
REPORT_DIR="$ROOT/stable_reports"
BIN_DIR="$ROOT/out_cov"
ZLIB_SRC="/home/minseo/alfha/targets/zlib/target"

MERGED_PROFDATA="$PROFILE_DIR/stable_unified.profdata"
TIMESTAMP=$(date '+%y%m%d_%H%M')
SUMMARY_FILE="$ROOT/../../analysis/logs/stable_coverage_report_${TIMESTAMP}.md"

echo "ðŸ” ALFHA zlib Stable Coverage Report Generator"
echo "=============================================="
echo "ðŸ“ Profile directory: $PROFILE_DIR"
echo "ðŸ“Š Report directory: $REPORT_DIR"
echo ""

mkdir -p "$REPORT_DIR"

# Detect LLVM tools
CLANG_MAJOR="$(clang --version | head -n1 | sed -n 's/.*clang version \([0-9]\+\).*/\1/p')"
LLVM_PROFDATA="llvm-profdata"
LLVM_COV="llvm-cov"

if [ -n "$CLANG_MAJOR" ] && command -v "llvm-profdata-$CLANG_MAJOR" >/dev/null 2>&1; then
  LLVM_PROFDATA="llvm-profdata-$CLANG_MAJOR"
fi
if [ -n "$CLANG_MAJOR" ] && command -v "llvm-cov-$CLANG_MAJOR" >/dev/null 2>&1; then
  LLVM_COV="llvm-cov-$CLANG_MAJOR"
fi

# Find non-empty profile files
PROFILE_FILES=()
for profile in "$PROFILE_DIR"/*.profraw; do
    if [ -f "$profile" ] && [ -s "$profile" ]; then
        PROFILE_FILES+=("$profile")
    fi
done

if [ ${#PROFILE_FILES[@]} -eq 0 ]; then
    echo "âŒ No valid profile files found"
    echo "Please run ./run_stable_coverage.sh first"
    exit 1
fi

echo "ðŸ“Š Found ${#PROFILE_FILES[@]} stable profiles to merge:"
for profile in "${PROFILE_FILES[@]}"; do
    size=$(stat -f%z "$profile" 2>/dev/null || stat -c%s "$profile" 2>/dev/null || echo "0")
    name=$(basename "$profile")
    printf "  %-30s %10s bytes\n" "$name" "$size"
done
echo ""

# Merge profiles
echo "ðŸ”„ Merging stable profiles..."
"$LLVM_PROFDATA" merge -sparse "${PROFILE_FILES[@]}" -o "$MERGED_PROFDATA"

merged_size=$(stat -f%z "$MERGED_PROFDATA" 2>/dev/null || stat -c%s "$MERGED_PROFDATA" 2>/dev/null || echo "0")
echo "âœ… Merged profile: ${merged_size} bytes"

# Find reference binary
REFERENCE_BINARY="$BIN_DIR/deflate_harness"
if [ ! -f "$REFERENCE_BINARY" ]; then
    REFERENCE_BINARY=$(ls "$BIN_DIR"/*_harness | head -1)
fi

echo "ðŸ“‹ Using $(basename "$REFERENCE_BINARY") as reference"
echo ""

# Generate reports
echo "ðŸ“Š Generating stable coverage reports..."

# Summary report with explicit source files
"$LLVM_COV" report "$REFERENCE_BINARY" \
    -instr-profile="$MERGED_PROFDATA" \
    -path-equivalence="$ZLIB_SRC","$ZLIB_SRC" \
    "$ZLIB_SRC"/*.c "$HARNESS_DIR"/*.c \
    > "$REPORT_DIR/stable_summary.txt"

# Detailed report with explicit source files
"$LLVM_COV" show "$REFERENCE_BINARY" \
    -instr-profile="$MERGED_PROFDATA" \
    -show-line-counts-or-regions \
    -show-branches=count \
    -path-equivalence="$ZLIB_SRC","$ZLIB_SRC" \
    "$ZLIB_SRC"/*.c "$HARNESS_DIR"/*.c \
    > "$REPORT_DIR/stable_detailed.txt"

# HTML report with explicit source files  
"$LLVM_COV" show "$REFERENCE_BINARY" \
    -instr-profile="$MERGED_PROFDATA" \
    -format=html \
    -output-dir="$REPORT_DIR/html" \
    -Xdemangler=c++filt \
    -path-equivalence="$ZLIB_SRC","$ZLIB_SRC" \
    "$ZLIB_SRC"/*.c "$HARNESS_DIR"/*.c

# Extract statistics
TOTAL_COVERAGE=$(grep -E "^TOTAL" "$REPORT_DIR/stable_summary.txt" | tail -1)

# Create markdown summary
cat > "$SUMMARY_FILE" << EOF
# ALFHA zlib Stable Coverage Report

**Generated:** $(date)  
**Target:** zlib 1.3.1.2  
**Stable Harnesses:** ${#PROFILE_FILES[@]} harnesses  
**Execution Mode:** Parallel with memory limits

## ðŸŽ¯ Overall Coverage Summary

\`\`\`
$TOTAL_COVERAGE
\`\`\`

## ðŸ“Š Stable Harnesses Used

EOF

for profile in "${PROFILE_FILES[@]}"; do
    harness_name=$(basename "$profile" .profraw)
    size=$(stat -f%z "$profile" 2>/dev/null || stat -c%s "$profile" 2>/dev/null || echo "0")
    echo "- **$harness_name**: ${size} bytes profile" >> "$SUMMARY_FILE"
done

cat >> "$SUMMARY_FILE" << EOF

## ðŸ” Key Improvements

### âœ… Stability Enhancements
- **Memory limits**: RSS limit set to 512MB per harness
- **Parallel execution**: ${PARALLEL_WORKERS:-4} workers for efficiency  
- **Error handling**: Graceful handling of crashes and timeouts
- **Profile validation**: Only non-empty profiles included

### ðŸ“ˆ Coverage Quality
- **Reliable data**: All included harnesses generated valid profiles
- **Comprehensive coverage**: Multiple deflate/inflate paths covered
- **Optimized runtime**: Faster execution with parallel processing

## ðŸ“ Generated Reports

- **Summary:** \`$REPORT_DIR/stable_summary.txt\`
- **Detailed:** \`$REPORT_DIR/stable_detailed.txt\`
- **HTML:** \`$REPORT_DIR/html/index.html\`

## ðŸŒ View Results

Open HTML report: \`file://$REPORT_DIR/html/index.html\`

## ðŸ’¡ Next Steps

1. **Add more stable harnesses** - Fix remaining crash issues
2. **Increase parallel workers** - Scale up for faster coverage  
3. **Extend runtime** - Run longer for deeper coverage

---
*Generated by ALFHA Stable Coverage System*
EOF

echo "âœ… Stable coverage report completed!"
echo ""
echo "ðŸ“Š Coverage Summary:"
echo "$TOTAL_COVERAGE"
echo ""
echo "ðŸ“ Generated files:"
echo "  ðŸ“„ Summary: $REPORT_DIR/stable_summary.txt"
echo "  ðŸ“‹ Detailed: $REPORT_DIR/stable_detailed.txt"  
echo "  ðŸŒ HTML: $REPORT_DIR/html/index.html"
echo "  ðŸ“ Markdown: $SUMMARY_FILE"
echo ""
echo "ðŸŒ View HTML: file://$REPORT_DIR/html/index.html"